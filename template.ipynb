{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of template.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayteeflick/nma_cn_flow_state/blob/update_function/template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxiMhxrvMqQ8"
      },
      "source": [
        "# Flow State Template Analysis File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atk2QuhRCn7i"
      },
      "source": [
        "General functions to use in all notebooks. Make a copy of this to start a new type of analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeXo3ijTMIxb"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qWJi-siDfYx"
      },
      "source": [
        "#title \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8F_e8RsMFRv"
      },
      "source": [
        "## Data Retrieval - spikes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VOCPJJFCk_i"
      },
      "source": [
        "#title Data retrieval - spikes\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh_K2aup8jrn"
      },
      "source": [
        "## Data retrieval - LFP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL13fYEYDl6d"
      },
      "source": [
        " \n",
        "import os, requests\n",
        "\n",
        "fname = ['steinmetz_st.npz']\n",
        "fname.append('steinmetz_wav.npz')\n",
        "fname.append('steinmetz_lfp.npz')\n",
        "\n",
        "url = [\"https://osf.io/4bjns/download\"]\n",
        "url.append(\"https://osf.io/ugm9v/download\")\n",
        "url.append(\"https://osf.io/kx3v9/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "dat_LFP = np.load('steinmetz_lfp.npz', allow_pickle=True)['dat']\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7UT7dyj_6R"
      },
      "source": [
        "`dat_LFP`, `dat_WAV`, `dat_ST` contain 39 sessions from 10 mice, data from Steinmetz et al, 2019, supplemental to the main data provided for NMA. Time bins for all measurements are 10ms, starting 500ms before stimulus onset (same as the main data). The followin fields are available across the three supplemental files. \n",
        "\n",
        "* `dat['lfp']`: recording of the local field potential in each brain area from this experiment, binned at `10ms`.\n",
        "* `dat['brain_area_lfp']`: brain area names for the LFP channels. \n",
        "* `dat['trough_to_peak']`: measures the width of the action potential waveform for each neuron. Widths `<=10` samples are \"putative fast spiking neurons\". \n",
        "* `dat['waveform_w']`: temporal components of spike waveforms. `w@u` reconstructs the time by channels action potential shape. \n",
        "* `dat['waveform_u]`: spatial components of spike waveforms.\n",
        "* `dat['ss']`: neurons by trials. Exact spikes times for each neuron and each trial, reference to the stimulus onset. A (neuron,trial) entry can be an empty list if that neuron did not fire at all on that trial. \n",
        "* `dat['%X%_passive']`: same as above for `X` = {`lfp`, `ss`} but for  passive trials at the end of the recording when the mouse was no longer engaged and stopped making responses. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFCTeF8P8JGs"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fogo6aADEKV6"
      },
      "source": [
        "# commmon functions\n",
        "\n",
        "def select_brois(data, brois, data_type, selection=True):\n",
        "  '''\n",
        "  Args:\n",
        "    data: a numpy array of the Steinmetz 2019 data\n",
        "    brois: a list of brain regions of interest\n",
        "    data_type: \"LFP\" or \"spikes\"\n",
        "    selection: if True, filters for sessions that contain all brois. If False, filters\n",
        "        for sessions that contain any of the brois\n",
        "  Returns:\n",
        "    an embedded 1-d numpy array, with length = number of filtered session\n",
        "  '''\n",
        "  selected_data = np.array([])\n",
        "\n",
        "  if data_type == \"LFP\":\n",
        "    brain_area = \"brain_area_lfp\"\n",
        "  elif data_type == \"spikes\":\n",
        "    brain_area = \"brain_area\"\n",
        "\n",
        "  if selection == True:\n",
        "    for i in range(len(data)):\n",
        "      if all(item in data[i][brain_area] for item in brois):\n",
        "        selected_data = np.hstack((selected_data, data[i]))\n",
        "  else:\n",
        "    for i in range(len(data)):\n",
        "      if any(item in data[i][brain_area] for item in brois):\n",
        "        selected_data = np.hstack((selected_data, data[i]))\n",
        "\n",
        "  return selected_data\n",
        "\n",
        "def sel_neurons():\n",
        "  print('todo')\n",
        "  return\n",
        "\n",
        "def spks_to_rate(spks):\n",
        "  print('todo')\n",
        "  return\n",
        "\n",
        "def butter_bandpass_backend(lowcut, highcut, fs, order=6):\n",
        "  nyq = 0.5 * fs\n",
        "  low = lowcut / nyq\n",
        "  high = highcut / nyq\n",
        "  b, a = butter(order, [low, high], btype='band')\n",
        "  return b, a\n",
        "\n",
        "def butter_bandpass_filter_good_func(data, lowcut, highcut, fs, order=6):\n",
        "  b, a = butter_bandpass_backend(lowcut, highcut, fs, order=order)\n",
        "  y = lfilter(b, a, data)\n",
        "  return y \n",
        "\n",
        "def get_behavioral_idx(recording_session):\n",
        "  '''\n",
        "  Args:\n",
        "    alldat: spiking data as loaded in originally \n",
        "    recording session: what recording session as an integer you want to pull behavioral indices for \n",
        "  Returns:\n",
        "    series of arrays that you can use to index behavior \n",
        "  '''\n",
        "  response = recording_session['response'] # right - nogo - left (-1, 0, 1)\n",
        "  vis_right = recording_session['contrast_right'] # 0 - low - high\n",
        "  vis_left = recording_session['contrast_left'] # 0 - low - high\n",
        "  gocue_idx = recording_session['gocue']\n",
        "  rt_idx = recording_session['reaction_time']\n",
        "  is_correct = np.sign(response)==np.sign(vis_left-vis_right)\n",
        "  return response, vis_right, vis_left, gocue_idx, rt_idx, is_correct\n",
        "\n",
        "def concatenate_lfp(brain_area_raw_dat,zeropadsize=0): \n",
        "  '''\n",
        "  Args:\n",
        "    data: a 2d array of raw brain area LFP should be 2d after you select a specific session and area to pull. \n",
        "    zeropadsize: if you'd like to add padding to the concatenation. Default is 0 (no padding)\n",
        "  Returns:\n",
        "    1D Array of Concatenated trials for a given brain area recording. \n",
        "  '''\n",
        "  concatenated_data = np.array([])\n",
        "  N = zeropadsize\n",
        "  for i in range(len(brain_area_raw_dat)):\n",
        "    single_trial = brain_area_raw_dat[i,:]\n",
        "    trial_padded = np.pad(single_trial,(N,N),'constant')\n",
        "    concatenated_data = np.concatenate([concatenated_data,trial_padded])\n",
        "  return concatenated_data\n",
        "\n",
        "def spikes_avg(data):\n",
        "  '''\n",
        "  Args:\n",
        "    data: a single session data frame from Steinmetz 2019 data\n",
        "  Returns:\n",
        "    A 2d numpy array of trial averages. Rows are neurons. Column are time step\n",
        "  '''\n",
        "  avg = np.mean(data['spks'], axis = 1)\n",
        "\n",
        "  return avg\n",
        "\n",
        "def add_avg(data):\n",
        "  \"\"\"\n",
        "  Adds the trial average to the data structure\n",
        "\n",
        "  Args: \n",
        "    data: a single session dataframe from Steinmetz\n",
        "  \"\"\"\n",
        "  data[\"spks_avg\"] = spikes_avg(data)\n",
        "  return data\n",
        "\n",
        "def multi_add_avg(alldat):\n",
        "  \"\"\"\n",
        "  Adds trial averages to all sessions in the dataframe\n",
        "  Args:\n",
        "    alldat: a numpy array of sessions\n",
        "  \"\"\"\n",
        "  for i in range(len(alldat)):\n",
        "    alldat[i] = add_avg(alldat[i])\n",
        "  return alldat\n",
        "\n",
        "def concat_trials(data, bin_start, bin_end):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    data: a single session data frame from Steinmetz 2019 data\n",
        "    bin_start, bin_end: integers indicating which bin to start and end at\n",
        "  Returns:\n",
        "    A 2d numpy array of with trials concatenated horizontally with shape N×TK \n",
        "    (number of neurons by number of time points times number of trials).\n",
        "  \"\"\"   \n",
        "  NN = len(data['spks'][0])\n",
        "  X = np.reshape(data['spks'][:,:,bin_start:end], (NN,-1))\n",
        "\n",
        "  return X"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2jZFBFKmKc1"
      },
      "source": [
        "## Testing Filter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izrYPXprmJwh"
      },
      "source": [
        "# brain regions of interest\n",
        "# brois = [\"ACA\", \"CA1\", \"DG\", \"MRN\", \"PL\",\"VISp\", \"ZI\"]\n",
        "brois = [\"PL\",\"VISp\"]\n",
        "\n",
        "filtered_spikes = select_brois(alldat, brois, \"spikes\")\n",
        "print(len(filtered_spikes))\n",
        "\n",
        "filtered_lfp = select_brois(dat_LFP, brois, \"LFP\")\n",
        "print(len(filtered_lfp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe4gZ1LvPfbR"
      },
      "source": [
        "##Testing Bandpass Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miw42j0jPa76"
      },
      "source": [
        "#pulling LFP Data of mouse 11 \n",
        "dat = dat_LFP[11]\n",
        "# Sample rate and desired cutoff frequencies (in Hz).\n",
        "fs = 100.0\n",
        "lowcut = 6.0\n",
        "highcut = 9.0\n",
        "filt_data = butter_bandpass_filter_good_func(dat['lfp'], lowcut, highcut, fs,order=5)\n",
        "#plotting \n",
        "test = np.mean(filt_data,axis=0)\n",
        "plt.plot(np.mean(test,axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "686g_02LLZxq"
      },
      "source": [
        "## Filter Spikes Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHkmZYvhLSan"
      },
      "source": [
        "# brain regions of interest\n",
        "brois = [\"ACA\", \"CA1\", \"DG\", \"MRN\", \"PL\",\"VISp\", \"ZI\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}