{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pca.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayteeflick/nma_cn_flow_state/blob/pca/pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxiMhxrvMqQ8"
      },
      "source": [
        "# Flow State PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atk2QuhRCn7i"
      },
      "source": [
        "General functions to use in all notebooks. Make a copy of this to start a new type of analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeXo3ijTMIxb"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qWJi-siDfYx"
      },
      "source": [
        "#title \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, filtfilt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8F_e8RsMFRv"
      },
      "source": [
        "## Data Retrieval - spikes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VOCPJJFCk_i"
      },
      "source": [
        "#title Data retrieval - spikes\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFCTeF8P8JGs"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fogo6aADEKV6"
      },
      "source": [
        "# commmon functions\n",
        "\n",
        "def select_brois(data, brois, data_type, selection=True):\n",
        "  '''\n",
        "  Args:\n",
        "    data: a numpy array of the Steinmetz 2019 data\n",
        "    brois: a list of brain regions of interest\n",
        "    data_type: \"LFP\" or \"spikes\"\n",
        "    selection: if True, filters for sessions that contain all brois. If False, filters\n",
        "        for sessions that contain any of the brois\n",
        "  Returns:\n",
        "    an embedded 1-d numpy array, with length = number of filtered session\n",
        "  '''\n",
        "  selected_data = np.array([])\n",
        "\n",
        "  if data_type == \"LFP\":\n",
        "    brain_area = \"brain_area_lfp\"\n",
        "  elif data_type == \"spikes\":\n",
        "    brain_area = \"brain_area\"\n",
        "\n",
        "  if selection == True:\n",
        "    for i in range(len(data)):\n",
        "      if all(item in data[i][brain_area] for item in brois):\n",
        "        selected_data = np.hstack((selected_data, data[i]))\n",
        "  else:\n",
        "    for i in range(len(data)):\n",
        "      if any(item in data[i][brain_area] for item in brois):\n",
        "        selected_data = np.hstack((selected_data, data[i]))\n",
        "\n",
        "  return selected_data\n",
        "\n",
        "def sel_neurons():\n",
        "  print('todo')\n",
        "  return\n",
        "\n",
        "def spks_to_rate(spks):\n",
        "  print('todo')\n",
        "  return\n",
        "\n",
        "def butter_bandpass_backend(lowcut, highcut, fs, order=6):\n",
        "  nyq = 0.5 * fs\n",
        "  low = lowcut / nyq\n",
        "  high = highcut / nyq\n",
        "  b, a = butter(order, [low, high], btype='band')\n",
        "  return b, a\n",
        "\n",
        "def butter_bandpass_filter_good_func(data, lowcut, highcut, fs, order=6):\n",
        "  b, a = butter_bandpass_backend(lowcut, highcut, fs, order=order)\n",
        "  y = filtfilt(b, a, data)\n",
        "  return y \n",
        "\n",
        "def get_behavioral_idx(recording_session):\n",
        "  '''\n",
        "  Args:\n",
        "    alldat: spiking data as loaded in originally \n",
        "    recording session: what recording session as an integer you want to pull behavioral indices for \n",
        "  Returns:\n",
        "    series of arrays that you can use to index behavior \n",
        "  '''\n",
        "  response = recording_session['response'] # right - nogo - left (-1, 0, 1)\n",
        "  vis_right = recording_session['contrast_right'] # 0 - low - high\n",
        "  vis_left = recording_session['contrast_left'] # 0 - low - high\n",
        "  gocue_idx = recording_session['gocue']\n",
        "  rt_idx = recording_session['reaction_time']\n",
        "  is_correct = np.sign(response)==np.sign(vis_left-vis_right)\n",
        "  return response, vis_right, vis_left, gocue_idx, rt_idx, is_correct\n",
        "\n",
        "def concatenate_lfp(brain_area_raw_dat,zeropadsize=0): \n",
        "  '''\n",
        "  Args:\n",
        "    data: a 2d array of raw brain area LFP should be 2d after you select a specific session and area to pull. \n",
        "    zeropadsize: if you'd like to add padding to the concatenation. Default is 0 (no padding)\n",
        "  Returns:\n",
        "    1D Array of Concatenated trials for a given brain area recording. \n",
        "  '''\n",
        "  concatenated_data = np.array([])\n",
        "  N = zeropadsize\n",
        "  for i in range(len(brain_area_raw_dat)):\n",
        "    single_trial = brain_area_raw_dat[i,:]\n",
        "    trial_padded = np.pad(single_trial,(N,N),'constant')\n",
        "    concatenated_data = np.concatenate([concatenated_data,trial_padded])\n",
        "  return concatenated_data\n",
        "\n",
        "def spikes_avg(data):\n",
        "  '''\n",
        "  Args:\n",
        "    data: a single session data frame from Steinmetz 2019 data\n",
        "  Returns:\n",
        "    A 2d numpy array of trial averages. Rows are neurons. Column are time step\n",
        "  '''\n",
        "  avg = np.mean(data['spks'], axis = 1)\n",
        "\n",
        "  return avg\n",
        "\n",
        "def add_avg(data):\n",
        "  '''\n",
        "  Adds the trial average to the data structure\n",
        "\n",
        "  Args: \n",
        "    data: a single session dataframe from Steinmetz\n",
        "  '''\n",
        "  data[\"spks_avg\"] = spikes_avg(data)\n",
        "  return data\n",
        "\n",
        "def multi_add_avg(alldat):\n",
        "  \"\"\"\n",
        "  Adds trial averages to all sessions in the dataframe\n",
        "  Args:\n",
        "    alldat: a numpy array of sessions\n",
        "  \"\"\"\n",
        "  for i in range(len(alldat)):\n",
        "    alldat[i] = add_avg(alldat[i])\n",
        "  return alldat\n",
        "\n",
        "def concat_trials(data, bin_start, bin_end):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    data: a single session data frame from Steinmetz 2019 data\n",
        "    bin_start, bin_end: integers indicating which bin to start and end at\n",
        "  Returns:\n",
        "    A 2d numpy array of with trials concatenated horizontally with shape NÃ—TK \n",
        "    (number of neurons by number of time points times number of trials).\n",
        "  \"\"\"   \n",
        "  NN = data.shape[0]\n",
        "  X = np.reshape(data[:,:,bin_start:bin_end], (NN,-1))\n",
        "\n",
        "  return X\n",
        "\n",
        "def trial_result(data):\n",
        "  '''\n",
        "  Args:\n",
        "    data: a single session data frame\n",
        "  Returns:\n",
        "    numpy logical arrarys corresponding to right trials, correct right, incorrect\n",
        "    right trials, miss right trials, no_go trials\n",
        "  '''\n",
        "  # response: right - nogo - left (-1, 0, 1)\n",
        "  # vis left/right 0 - low - high\n",
        "  response, vis_right, vis_left, gocue_idx, rt_idx, is_correct = get_behavioral_idx(data)\n",
        "  ind = {}\n",
        "\n",
        "  # trial types\n",
        "  ind[\"right_go\"] = np.array(vis_right > vis_left)\n",
        "  ind[\"left_go\"] = np.array(vis_left > vis_right)\n",
        "  ind[\"nogo\"] = np.logical_and(vis_left == 0, vis_right == 0)\n",
        "  ind[\"equal\"] = np.logical_and(vis_right >0, vis_right == vis_left)\n",
        "\n",
        "  # right trials by response\n",
        "  ind[\"right_cor\"] = np.logical_and(response == -1, vis_right > vis_left)\n",
        "  ind[\"right_error\"] = np.logical_and(response == 1, vis_right > vis_left)\n",
        "  ind[\"right_miss\"] = np.logical_and(response == 0, vis_right > vis_left)\n",
        "\n",
        "  # left trials by response\n",
        "  ind[\"left_cor\"] = np.logical_and(response == 1, vis_right < vis_left)\n",
        "  ind[\"left_error\"] = np.logical_and(response == -1, vis_right < vis_left)\n",
        "  ind[\"left_miss\"] = np.logical_and(response == 0, vis_right < vis_left)\n",
        "\n",
        "  # nogo trials by response\n",
        "  ind[\"nogo_cor\"] = np.logical_and(response == 0, ind[\"nogo\"])\n",
        "  ind[\"nogo_error\"] = np.logical_and(response != 0, ind[\"nogo\"])\n",
        "\n",
        "  return ind"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCJpxep5oiWc"
      },
      "source": [
        "## Select Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmmAAoehqHS"
      },
      "source": [
        "dat = alldat[11]\n",
        "ind = trial_result(dat)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEQutEKAimIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f6d884-961d-404d-d8e3-e38fbb6c766e"
      },
      "source": [
        "print(sum(ind['right_go']))\n",
        "print(sum(ind['left_go']))\n",
        "print(sum(ind['nogo']))\n",
        "print(sum(ind['equal']))\n",
        "print(len(dat[\"response\"]))\n",
        "print(sum(ind[\"nogo_error\"]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111\n",
            "103\n",
            "108\n",
            "18\n",
            "340\n",
            "58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b62qPZBeoqCk"
      },
      "source": [
        "right_trials = dat[\"spks\"][:, ind[\"right_go\"], :]\n",
        "X = concat_trials(right_trials, 51, 130)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHe4N0n3o7P6",
        "outputId": "1318d48d-a547-443e-fb9e-8fc99bcddbaf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(698, 8769)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a923wL3irIVR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}